<!-- 99758a2a-9365-4041-af8b-fd9cd430091f 1fd77d00-7bd7-4e56-b423-baf20b0e2356 -->
# Project Chimera â€“ nanochat hypertraining plan

## Summary

Implement synthetic data generation via OpenRouter, add a DPO trainer, wire both into `speedrun.sh`, support a trader SFT dataset (mixed with SmolTalk for robustness), add a new `dpo` checkpoint source, and extend reporting.

## Changes

### 1) Synthetic data (OpenRouter)

- New `scripts/synthetic_data_gen.py`:
- Reads env `OPENROUTER_API_KEY` (required) and `OPENROUTER_MODELS` (comma-separated model list; pick first available or use default).
- Uses OpenAI SDK v1 with `base_url="https://openrouter.ai/api/v1"`.
- Outputs JSONL:
  - `~/.cache/nanochat/datasets/trader_sft_data.jsonl`: lines are `{ "messages": [ {"role":"system"|"user"|"assistant", "content": str }, ... ] }`.
  - `~/.cache/nanochat/datasets/trader_dpo_data.jsonl`: lines are `{ "prompt": str, "chosen": str, "rejected": str }`.
- Generates persona-faithful SFT conversations and Master/Apprentice DPO pairs with retry/backoff and progress bars.

### 2) Trader SFT Task

- New `tasks/trader_sft.py`:
- Class `TraderSFT(Task)` loads the SFT JSONL, deterministic 90/10 split, returns `{"messages": ...}`.

### 3) SFT dataset switch & mixing

- Edit `scripts/chat_sft.py`:
- Add config keys (overridable via configurator):
  - `sft_dataset = "mixture" | "trader" | "trader_mix"` (default remains `"mixture"`).
  - `trader_data_path = None`, `trader_val_fraction = 0.1`.
  - `sft_mix_trader = 1`, `sft_mix_smoltalk = 1` (weights when `trader_mix`).
- If `trader`: train/val from `TraderSFT` only.
- If `trader_mix`: build a `TaskMixture([TraderSFT(...), SmolTalk(split="train", stop=10_000)])` with weighted sampling by duplicating entries according to weights.
- Else keep existing mixture unchanged.

### 4) DPO trainer

- New `scripts/dpo_train.py`:
- Loads SFT model via `load_model("sft", device, phase="train")` and constructs a frozen reference copy.
- Reads DPO JSONL, builds two conversations per item (prompt+chosen, prompt+rejected), tokenizes via `tokenizer.render_conversation`.
- Computes per-sequence log-probs over assistant tokens only; implements DPO loss with `beta` (default 0.1).
- Uses `model.setup_optimizers(...)`; bfloat16 autocast; truncates to `min(max_length, model.config.sequence_len)`.
- Saves to `chatdpo_checkpoints/d{depth}` via `save_checkpoint`, logs a `"Chat DPO"` section to report.

### 5) Checkpoint mapping

- Edit `nanochat/checkpoint_manager.py`: add `"dpo": "chatdpo_checkpoints"` to `load_model` mapping.

### 6) Reporting

- Edit `nanochat/report.py`:
- Add `chat-dpo.md` and `chat-evaluation-dpo.md` to `EXPECTED_FILES` (after SFT files).
- Include `"dpo"` in the summary stages between `"sft"` and `"rl"` and extract metrics from `"Chat evaluation dpo"`.

### 7) speedrun integration

- Edit `speedrun.sh`:
- After environment setup and tokenizer build, add:
  - `echo "--- Generating Chimera SFT and DPO datasets (OpenRouter) ---"`
  - `python -m scripts.synthetic_data_gen --sft-examples 5000 --dpo-examples 10000`
- Change SFT call to use trader mix:
  - `torchrun ... -m scripts.chat_sft -- --run=$WANDB_RUN --sft_dataset=trader_mix --sft_mix_trader=1 --sft_mix_smoltalk=1`
- After SFT eval, add DPO stage and eval:
  - `torchrun ... -m scripts.dpo_train`
  - `torchrun ... -m scripts.chat_eval -- -i dpo`

### 8) Dependencies

- Edit `pyproject.toml` to add:
- `openai>=1.40.0`
- `tqdm>=4.66.0`

## Notes

- Environment:
- Require `OPENROUTER_API_KEY`.
- Optional `OPENROUTER_MODELS` (e.g., `openai/gpt-4o-mini, anthropic/claude-3.5-sonnet`).
- We intentionally mix TraderSFT with SmolTalk to preserve general chat ability while aligning persona; DPO then sharpens preference alignment.

### To-dos

- [ ] Add openai and tqdm to pyproject.toml dependencies
- [ ] Create scripts/synthetic_data_gen.py using OpenRouter env
- [ ] Create tasks/trader_sft.py JSONL-backed Task
- [ ] Add dataset switches and mixing to scripts/chat_sft.py
- [ ] Create scripts/dpo_train.py with DPO loss and saving
- [ ] Map 'dpo' to chatdpo_checkpoints in checkpoint_manager
- [ ] Include DPO sections and stage in report.py
- [ ] Invoke generator, use trader_mix SFT, add DPO + eval